---
title: "PMS data"
output: html_notebook
author: "Sofie Raeymakers"
date: "`r Sys.setlocale('LC_TIME', 'C'); format(Sys.time(), '%d\\\\. %B %Y')`"
output:
  html_document:
    code_download: yes
    code_folding: hide
    number_sections: yes
    toc: yes
    toc_depth: 2
    toc_float: yes
bibliography: references.bib
---

```{r libraries}
# we will first write some pseudocode to describe what we want to do
#upload files
#find best linear model to represent data with AI

#     PSS ~ PMSScore*Moment + (1|Subject)
# 
#     PSS deppendent variablle
#     pMS = 1 geen PMS
#     keer moment: moment v afname
#     1 out of subject: random effect toevoegen
#     straks factoren vd PMS score en van moment: hoeveel levels? 
#       formules van doen
#     laten weten welke formule beste
#     

    
#### Settings & Packages #### -----------------------------------------------------
rm(list = ls())
options(contrasts = c("contr.sum","contr.poly")) #use this for the p value of the t test
library(lme4)
library(lmerTest)
library(effects)
library(dplyr)
library(car)
library(emmeans)
library(fitdistrplus)
library(dplyr)
library(car)
# library(MuMIn)
library(ggplot2)
library(ggsignif)
library(gridExtra)
library(tidyverse)
library(ggeffects)
library(pander)
recode <- dplyr::recode
# Suppress summarize info
options(dplyr.summarise.inform = FALSE)
count <- dplyr::count 
# set the theme to theme_bw for all ggplot2 figures
theme_set(theme_bw())
# create folder to save figures
if (!dir.exists("figures")) dir.create("figures")
```



```{r load-data}
#### IMPORT DATA & INSPECTION #### -------------------------------------------------------------
knitr::opts_knit$set(root.dir = dirname(rstudioapi::getActiveDocumentContext()$path))# Set working directory to current directory
# setwd("C:\Users\ASUSTeK\OneDrive\2021-2022\internship\projects")
data <- read.csv("Data/allPMSdata.csv", header=TRUE)
# data <- read.table("Data/allPMSdata.csv",sep="\t", header=TRUE)


# from wide to long
#check if subject column is a facctor
str(data)
head(data)
# data <-as.numeric(data)
data$Subject <- factor(data$ID)
typeof(data$Subject)
head (data$Subject)

#we make a new variable that has value 1 for the first TestMoment and 2 for the second TestMoment
#These moments were counterbalanced
#when the order was B-A and the moment is B, this means it is the first test moment
#and vice versa for A-B and moment A. 


data$TestMoment[data$Order == "A-B" & data$Moment == "A"] = 1
data$TestMoment[data$Order == "B-A" & data$Moment == "A"] = 2
data$TestMoment[data$Order == "A-B" & data$Moment == "B"] = 2
data$TestMoment[data$Order == "B-A" & data$Moment == "B"] = 1
#check if there are still values missing (NA)
sum(is.na(data$TestMoment))


# Check whether R recognizes the variable types correctly
#we make factors of the independable variables

data$PMSScore <- factor(data$PMSScore)

data$Moment <- factor(data$TestMoment)

# Exclude data?


# Define the formula for the model & check which model fits the data best
Formula <- PSS ~ PMSScore*TestMoment + (1|Subject)


d0.1 <- lmer(Formula,data=data)
d0.2 <- glmer(Formula,data=data, family = gaussian(link = "inverse"),glmerControl(optimizer= "bobyqa", optCtrl = list(maxfun = 100000)),nAGQ=0)
d0.3 <- glmer(Formula,data=data, family = gaussian(link = "log"),glmerControl(optimizer= "bobyqa", optCtrl = list(maxfun = 100000)),nAGQ=0)

d0.4 <- glmer(Formula,data=data, family = Gamma(link = "identity"),glmerControl(optimizer= "bobyqa", optCtrl = list(maxfun = 100000)),nAGQ=0)
d0.5 <- glmer(Formula,data=data, family = Gamma(link = "inverse"),glmerControl(optimizer= "bobyqa", optCtrl = list(maxfun = 100000)),nAGQ=0)
d0.6 <- glmer(Formula,data=data, family = Gamma(link = "log"),glmerControl(optimizer= "bobyqa", optCtrl = list(maxfun = 100000)),nAGQ=0)

d0.7 <- glmer(Formula,data=data, family = inverse.gaussian(link = "identity"),glmerControl(optimizer= "bobyqa", optCtrl = list(maxfun = 100000)),nAGQ=0)
d0.8 <- glmer(Formula,data=data, family = inverse.gaussian(link = "inverse"),glmerControl(optimizer= "bobyqa", optCtrl = list(maxfun = 100000)),nAGQ=0)
d0.9 <- glmer(Formula,data=data, family = inverse.gaussian(link = "log"),glmerControl(optimizer= "bobyqa", optCtrl = list(maxfun = 100000)),nAGQ=0)


# Remove the models that produced errors in the line below, the one with the lowest value is the best fitting model
tabel <- cbind(AIC(d0.1), AIC(d0.2), AIC(d0.3), AIC(d0.4), AIC(d0.5), AIC(d0.6), AIC(d0.7), AIC(d0.8), AIC(d0.9))
utils::View(tabel)
#d0.1 has the lowest AIC. so general linear model with inverse gaussian is the best fitting model

```

``` {r statistics}
  print(Anova(d0.3)) # Run Anova, double square brackets because of list properties
# Analysis of Deviance Table (Type II Wald chisquare tests)
# 
# Response: PSS
#                        Chisq Df Pr(>Chisq)    
# PMSScore              5.5924  2    0.06104 .  
# TestMoment          197.4098  1    < 2e-16 ***
# PMSScore:TestMoment 179.7476  2    < 2e-16 ***
# ---
# Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

  print("Stats")
  print(emmeans(d0.3, pairwise ~ TestMoment , adjust ="fdr", type="response"))
  
#    TestMoment response    SE  df asymp.LCL asymp.UCL
#           1     30.3 0.331 Inf      29.7      31.0
#           2     30.1 0.329 Inf      29.5      30.8
# 
# Results are averaged over the levels of: PMSScore 
# Confidence level used: 0.95 
# Intervals are back-transformed from the log scale 
# 
# $contrasts
#  contrast ratio       SE  df null z.ratio p.value
#  1 / 2    1.006 0.001256 Inf    1   5.104  <.0001
# 
# Results are averaged over the levels of: PMSScore 
# Tests are performed on the log scale 

```
```{r new variable Volgorde}



```
